/**
 * Environment-aware performance testing utilities
 * Provides adaptive thresholds and meaningful performance monitoring
 */

export interface PerformanceConfig {
    environment: 'local' | 'ci' | 'production'
    multiplier: number
    baseThresholds: {
        render: {
            simple: number
            complex: number
        }
        interaction: {
            click: number
            rapid: number
        }
        memory: {
            basic: number
            stress: number
        }
    }
}

/**
 * Detect current environment and return appropriate config
 */
export function getPerformanceConfig(): PerformanceConfig {
    const isCI = process.env.CI === 'true'
    const isProduction = process.env.NODE_ENV === 'production'
    const isGitHubActions = process.env.GITHUB_ACTIONS === 'true'

    // Base thresholds for optimal local development environment
    const baseThresholds = {
        render: {
            simple: 30, // Simple component render (increased from 25)
            complex: 60, // Complex component with all features (increased from 50)
        },
        interaction: {
            click: 35, // Single user interaction (increased from 30)
            rapid: 200, // Multiple rapid interactions (increased from 150)
        },
        memory: {
            basic: 3, // Basic memory operations
            stress: 30, // Stress test operations (increased from 20)
        },
    }

    if (isCI || isGitHubActions) {
        return {
            environment: 'ci',
            multiplier: 3.0, // CI environments are typically 3x slower
            baseThresholds,
        }
    }

    if (isProduction) {
        return {
            environment: 'production',
            multiplier: 1.5, // Production builds are optimized but still allow some variance
            baseThresholds,
        }
    }

    return {
        environment: 'local',
        multiplier: 2.0, // Local development with some tolerance
        baseThresholds,
    }
}

/**
 * Get environment-adjusted threshold for a specific performance metric
 */
export function getPerformanceThreshold(
    category: keyof PerformanceConfig['baseThresholds'],
    metric: string
): number {
    const config = getPerformanceConfig()
    const baseThreshold = (
        config.baseThresholds[category] as Record<string, number>
    )[metric]

    if (!baseThreshold) {
        throw new Error(`Unknown performance metric: ${category}.${metric}`)
    }

    return Math.ceil(baseThreshold * config.multiplier)
}

/**
 * Enhanced performance measurement with environment context
 */
export async function measurePerformanceWithContext<T>(
    operation: () => Promise<T> | T,
    category: keyof PerformanceConfig['baseThresholds'],
    metric: string
): Promise<{
    result: T
    duration: number
    threshold: number
    passed: boolean
    environment: string
    recommendation?: string
}> {
    const config = getPerformanceConfig()
    const threshold = getPerformanceThreshold(category, metric)

    const start = performance.now()
    const result = await operation()
    const end = performance.now()
    const duration = end - start

    const passed = duration <= threshold

    let recommendation: string | undefined
    if (!passed) {
        const baseThreshold = (
            config.baseThresholds[category] as Record<string, number>
        )[metric]
        if (duration <= baseThreshold * 1.2) {
            recommendation = 'Performance is acceptable but could be optimized'
        } else if (duration <= baseThreshold * 2) {
            recommendation =
                'Performance degradation detected - investigate component optimization'
        } else {
            recommendation =
                'Significant performance issue - requires immediate attention'
        }
    }

    return {
        result,
        duration,
        threshold,
        passed,
        environment: config.environment,
        recommendation,
    }
}

/**
 * Performance regression detection
 * Compares current performance against baseline
 */
export class PerformanceBaseline {
    private static baselines = new Map<string, number>()

    static record(testName: string, duration: number): void {
        this.baselines.set(testName, duration)
    }

    static compare(
        testName: string,
        currentDuration: number
    ): {
        baseline: number | null
        regression: number | null
        isRegression: boolean
    } {
        const baseline = this.baselines.get(testName)
        if (!baseline) {
            this.record(testName, currentDuration)
            return { baseline: null, regression: null, isRegression: false }
        }

        const regression = ((currentDuration - baseline) / baseline) * 100
        const isRegression = regression > 20 // 20% regression threshold

        // Update baseline if performance improved
        if (currentDuration < baseline) {
            this.record(testName, currentDuration)
        }

        return { baseline, regression, isRegression }
    }
}

/**
 * Performance monitoring for production
 */
export function createPerformanceMonitor() {
    const measurements: Array<{
        component: string
        operation: string
        duration: number
        timestamp: number
        environment: string
    }> = []

    return {
        measure: async <T>(
            component: string,
            operation: string,
            fn: () => Promise<T> | T
        ): Promise<T> => {
            const start = performance.now()
            const result = await fn()
            const end = performance.now()

            measurements.push({
                component,
                operation,
                duration: end - start,
                timestamp: Date.now(),
                environment: getPerformanceConfig().environment,
            })

            return result
        },

        getReport: () => ({
            measurements: [...measurements],
            summary: {
                totalMeasurements: measurements.length,
                averageDuration:
                    measurements.reduce((sum, m) => sum + m.duration, 0) /
                    measurements.length,
                slowestOperation: measurements.reduce((slowest, current) =>
                    current.duration > slowest.duration ? current : slowest
                ),
                componentStats: measurements.reduce(
                    (stats, m) => {
                        if (!stats[m.component]) {
                            stats[m.component] = {
                                count: 0,
                                totalDuration: 0,
                                operations: {},
                            }
                        }
                        stats[m.component].count++
                        stats[m.component].totalDuration += m.duration

                        if (!stats[m.component].operations[m.operation]) {
                            stats[m.component].operations[m.operation] = {
                                count: 0,
                                totalDuration: 0,
                            }
                        }
                        stats[m.component].operations[m.operation].count++
                        stats[m.component].operations[
                            m.operation
                        ].totalDuration += m.duration

                        return stats
                    },
                    {} as Record<
                        string,
                        {
                            count: number
                            totalDuration: number
                            operations: Record<
                                string,
                                {
                                    count: number
                                    totalDuration: number
                                }
                            >
                        }
                    >
                ),
            },
        }),

        clear: () => {
            measurements.length = 0
        },
    }
}

/**
 * Custom assertion for performance testing
 */
export function assertPerformanceWithContext(
    duration: number,
    category: keyof PerformanceConfig['baseThresholds'],
    metric: string,
    testName?: string
): void {
    const threshold = getPerformanceThreshold(category, metric)
    const config = getPerformanceConfig()

    // Record for regression detection
    if (testName) {
        const regression = PerformanceBaseline.compare(testName, duration)
        if (regression.isRegression) {
            console.warn(
                `Performance regression detected in ${testName}: ` +
                    `${regression.regression?.toFixed(1)}% slower than baseline ` +
                    `(${duration.toFixed(2)}ms vs ${regression.baseline?.toFixed(2)}ms)`
            )
        }
    }

    if (duration > threshold) {
        const baseThreshold = (
            config.baseThresholds[category] as Record<string, number>
        )[metric]
        const message = [
            `Performance test failed: ${duration.toFixed(2)}ms > ${threshold}ms`,
            `Environment: ${config.environment} (${config.multiplier}x multiplier)`,
            `Base threshold: ${baseThreshold}ms`,
            testName ? `Test: ${testName}` : '',
        ]
            .filter(Boolean)
            .join('\n')

        throw new Error(message)
    }
}

/**
 * Performance test wrapper that provides context and better error messages
 */
export function performanceTest(
    name: string,
    category: keyof PerformanceConfig['baseThresholds'],
    metric: string,
    testFn: () => Promise<void> | void
) {
    return async () => {
        const config = getPerformanceConfig()
        const threshold = getPerformanceThreshold(category, metric)

        console.log(
            `Running performance test: ${name}\n` +
                `Environment: ${config.environment}\n` +
                `Threshold: ${threshold}ms (base: ${(config.baseThresholds[category] as Record<string, number>)[metric]}ms × ${config.multiplier})`
        )

        await testFn()
    }
}
